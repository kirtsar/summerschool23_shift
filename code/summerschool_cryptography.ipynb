{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.combinatorics import Permutation, PermutationGroup\n",
    "import numpy as np\n",
    "import math\n",
    "import sympy\n",
    "import sympy.functions.combinatorial.numbers as math_num\n",
    "from scipy.stats import chisquare\n",
    "from scipy.stats import chi2\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5c561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x, y, r=5): # x - O, y - E\n",
    "    m = 0\n",
    "    s = 0\n",
    "    for i in range(len(x)):\n",
    "        m += i*x[i]\n",
    "        s += x[i]\n",
    "    m = int(m/s) # the center of distr\n",
    "    # print(m)\n",
    "    left_x = [0 for k in range(m+1)] # should be croped\n",
    "    left_y = [0 for k in range(m+1)] #\n",
    "    # to the right\n",
    "    i = 0\n",
    "    k = 0\n",
    "    while i <= m:\n",
    "        s1 = x[i]\n",
    "        s2 = y[i]\n",
    "        if x[i] < r:\n",
    "            while s1 < r:\n",
    "                i += 1\n",
    "                s1 += x[i]\n",
    "                s2 += y[i]\n",
    "        left_x[k] = s1\n",
    "        left_y[k] = s2\n",
    "        i += 1\n",
    "        k += 1\n",
    "    # to the left\n",
    "    right_x = [0 for k in range(len(x) - m)]\n",
    "    right_y = [0 for k in range(len(x) - m)]\n",
    "    k = len(x) - m - 1\n",
    "    i = len(x) - 1\n",
    "    while i > m:\n",
    "        s1 = x[i]\n",
    "        s2 = y[i]\n",
    "        if x[i] < r:\n",
    "            while s1 < r:\n",
    "                i -= 1\n",
    "                s1 += x[i]\n",
    "                s2 += y[i]\n",
    "        right_x[k] = s1\n",
    "        right_y[k] = s2\n",
    "        i -= 1\n",
    "        k -= 1\n",
    "    \n",
    "    while left_x[-1] == 0:\n",
    "        left_x.pop()\n",
    "        left_y.pop()\n",
    "        \n",
    "    while right_x[0] == 0:\n",
    "        del right_x[0]\n",
    "        del right_y[0]\n",
    "    \n",
    "    return (left_x + right_x, left_y + right_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c375db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi(O, E, print_mode=False):\n",
    "    if print_mode:\n",
    "        print(O)\n",
    "        print(E)\n",
    "    O,E = conv(O, E)\n",
    "    if print_mode:\n",
    "        print(O)\n",
    "        print(E)\n",
    "    r = 0\n",
    "    for i in tqdm(range(len(O))):\n",
    "        r += (O[i] - E[i])**2/E[i]\n",
    "    return (r, len(O))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a11ed77",
   "metadata": {},
   "source": [
    "## Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde77c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # длина подстановки нужно выявить зависимость n ~ N, с сохранением удовлетворения критериям оценки\n",
    "N = 2**10 # размер выборки подстановок\n",
    "\n",
    "num_of_cycles = [0 for k in range(n+1)]\n",
    "num_of_fixed_points = [0 for k in range(n+1)]\n",
    "num_of_shortest_cycle = [0 for k in range(n+1)]\n",
    "num_of_inversions = [0 for k in range(int(n*(n-1)/2) + 1)]\n",
    "# num_of_orders = [0 for k in range(int(sympy.exp(n/sympy.exp(1))) + 1)]\n",
    "# num_of_orders = {}\n",
    "\n",
    "for i in tqdm(range(N)):\n",
    "    a = Permutation(np.random.permutation(n))\n",
    "    #cycle_num = a.cycles\n",
    "    #num_of_cycles[a.cycles] += 1\n",
    "    #if 1 in a.cycle_structure.keys():\n",
    "    #    num_of_fixed_points[a.cycle_structure[1]]  += 1\n",
    "    #else:\n",
    "    #    num_of_fixed_points[0] += 1\n",
    "    num_of_shortest_cycle[min(a.cycle_structure.keys())] += 1 \n",
    "#    order = 1\n",
    "#    for x in list(a.cycle_structure.keys()):\n",
    "#        order = np.lcm(order, x)\n",
    "#    if order in num_of_orders:\n",
    " #       num_of_orders[order] += 1\n",
    " #   else:\n",
    " #       num_of_orders[order] = 1\n",
    "    # num_of_inversions[a.inversions()] += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "#print(num_of_cycles)\n",
    "#print(num_of_fixed_points)\n",
    "print(num_of_shortest_cycle)\n",
    "#print(num_of_orders)\n",
    "# print(num_of_inversions)\n",
    "\n",
    "#print(a)\n",
    "#print(a.list())\n",
    "#print(a.inversions())\n",
    "#print(a.is_even)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231fe63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a68a4354",
   "metadata": {},
   "source": [
    "## Comparison of statistical distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b52127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кратчайший цикл имеет длину k\n",
    "\n",
    "def expindex(x, M):\n",
    "    res = x\n",
    "    for i in range(2, M + 1):\n",
    "        res += (x**i) / i\n",
    "    return -res\n",
    "\n",
    "def nthcoeff(f, x, n):\n",
    "    res = sympy.diff(f, x, n)\n",
    "    return res.subs(x, 0) / math.factorial(n)\n",
    "\n",
    "def get_polynom_for_cycle_length(M, n): \n",
    "    x = sympy.Symbol('x')\n",
    "    f = 1 - sympy.exp(-x) if  M == 0 else sympy.exp(expindex(x, M)) - sympy.exp(expindex(x, M + 1))\n",
    "    return nthcoeff(f / (1 - x), x, n)\n",
    "\n",
    "def gen_prob_of_shortest_cycles(n):\n",
    "    t = time.perf_counter()\n",
    "    short_cycle_length_exp = [0] * n\n",
    "    for i in tqdm(range(math.floor(n / 2) + 1)):\n",
    "        short_cycle_length_exp[i] = get_polynom_for_cycle_length(i, n) \n",
    "    short_cycle_length_exp[n-1] = get_polynom_for_cycle_length(n-1, n)\n",
    "    exp = np.array(np.array([float(i) for i in short_cycle_length_exp]))\n",
    "    return exp\n",
    "\n",
    "def gen_prob_of_shortest_cycles2(n):\n",
    "    exp = [0] * (n+1)\n",
    "    for i in range(1, math.floor(n / 2)):\n",
    "        exp[i+1] = math.exp(-sympy.harmonic(i)) - math.exp(-sympy.harmonic(i+1))\n",
    "    exp[1] = 1 - math.exp(-1)\n",
    "    exp[n] = 1 / n\n",
    "    return exp\n",
    "\n",
    "# inversion \n",
    "\n",
    "def gen_num_of_inversions(n):\n",
    "    result = [1]\n",
    "    for i in tqdm(range(1, n)):\n",
    "        prev = result[:]\n",
    "        result = [0] * int(1 + ((i + 1) * 0.5) * (i))\n",
    "        m = [1] * (i + 1)\n",
    "        for j in range(len(m)):\n",
    "            for k in range(len(prev)):\n",
    "                result[k+j] += m[j] * prev[k]\n",
    "    return result\n",
    "\n",
    "# inversion N*K - dynamic programming, recursive\n",
    "\n",
    "def mahonian_triangle(n): # to n inclusive\n",
    "    if exists('./E_num_of_inversions.pkl'):\n",
    "        with open('E_num_of_inversions.pkl', 'rb') as f:\n",
    "            E_num_of_inversions = pickle.load(f)\n",
    "    else:\n",
    "        E_num_of_inversions = {1: [1], 2: [1, 1]}\n",
    "    \n",
    "    # print('dict len', len(E_num_of_inversions.keys()))\n",
    "\n",
    "    for i in tqdm(range(len(E_num_of_inversions.keys()), n + 1)):\n",
    "        k = math.floor(((i+1)*i/2)/2) + 1\n",
    "        arr1 = E_num_of_inversions[i]\n",
    "        arr = [0 for c in range(0, k)]\n",
    "        for c in range(0, k):\n",
    "            v = 0\n",
    "            while (c - v >= 0) & (v <= i): \n",
    "                arr[c] += arr1[c-v]\n",
    "                v += 1\n",
    "        E_num_of_inversions[i+1] = arr[:len(arr)- int(((int(i+1)*i/2) + 1)%2)] + arr[::-1]\n",
    "        \n",
    "    with open('E_num_of_inversions.pkl', 'wb') as f:\n",
    "            pickle.dump(E_num_of_inversions, f)\n",
    "    return E_num_of_inversions\n",
    "\n",
    "def mah_number(n): # to n inclusive\n",
    "    if exists('./E_muh.pkl'):\n",
    "        with open('E_muh.pkl', 'rb') as f:\n",
    "            E_muh = pickle.load(f)\n",
    "    else:\n",
    "        E_muh = [1]\n",
    "    \n",
    "    # print('dict len', len(E_num_of_inversions.keys()))\n",
    "    l = round(math.sqrt(2*len(E_muh))) \n",
    "    print(l)\n",
    "    \n",
    "    for i in tqdm(range(l, n)):\n",
    "        k = math.floor(((i+1)*i/2)/2) + 1\n",
    "        arr1 = E_muh\n",
    "        arr = [0 for c in range(0, k)]\n",
    "        for c in range(0, k):\n",
    "            v = 0\n",
    "            while (c - v >= 0) & (v <= i): \n",
    "                arr[c] += arr1[c-v]\n",
    "                v += 1\n",
    "        E_muh = arr[:len(arr)- int(((int(i+1)*i/2) + 1)%2)] + arr[::-1]\n",
    "        if i % 10 == 0:\n",
    "            with open('E_muh.pkl', 'wb') as f:\n",
    "                pickle.dump(E_muh, f)\n",
    "            print(\"Saved\")\n",
    "        \n",
    "    return E_muh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73928cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    " if exists('./1024_mah.pkl'):\n",
    "        with open('1024_mah.pkl', 'rb') as f:\n",
    "            E_num_of_inversions_1024 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(E_num_of_inversions_1024[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf174268",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists('./E_prob_of_fixed_points.pkl'):\n",
    "    with open('E_prob_of_fixed_points.pkl', 'rb') as f:\n",
    "        E_prob_of_fixed_points = pickle.load(f)\n",
    "else:\n",
    "    E_prob_of_fixed_points = {}\n",
    "\n",
    "if exists('./E_prob_of_cycles.pkl'):\n",
    "    with open('E_prob_of_cycles.pkl', 'rb') as f:\n",
    "        E_prob_of_cycles = pickle.load(f)\n",
    "else:\n",
    "    E_prob_of_cycles = {}\n",
    "    \n",
    "if exists('./E_prob_of_shortest_cycle.pkl'):  \n",
    "    with open('E_prob_of_shortest_cycle.pkl', 'rb') as f:\n",
    "        E_prob_of_shortest_cycle = pickle.load(f)\n",
    "else:\n",
    "    E_prob_of_shortest_cycle = {}\n",
    "\n",
    "# Неподвижные точки\n",
    "def FP_criteria(num_of_fixed_points, n, N, alpha=0.05, print_mode=False):\n",
    "    if n not in E_prob_of_fixed_points:\n",
    "        E_prob_of_fixed_points[n] = [((1 / math.factorial(k)) * (sympy.subfactorial(n - k) / math.factorial(n - k))) for k in range(n+1)]\n",
    "        with open('E_prob_of_fixed_points.pkl', 'wb') as f:\n",
    "            pickle.dump(E_prob_of_fixed_points, f)\n",
    "    E_num_of_fixed_points = [ x*N  for x in E_prob_of_fixed_points[n]]\n",
    "    \n",
    "    (num_of_fixed_points_stat, points_array_len) = chi(num_of_fixed_points, E_num_of_fixed_points, print_mode)\n",
    "\n",
    "    points_quantile = chi2.ppf(1-0.05, df=points_array_len-1)\n",
    "    p_value = chi2.sf(float(num_of_fixed_points_stat), int(points_array_len-1))\n",
    "    if print_mode:\n",
    "        print(\"Квантиль степени \" + str(points_array_len - 1) + \" = \" + str(points_quantile))\n",
    "        print(\"Статистика для k неподвижных точек = \" + str(num_of_fixed_points_stat))\n",
    "        print(\"p-value = \" + str(p_value))\n",
    "    else:\n",
    "        return (num_of_fixed_points_stat, points_quantile, p_value)\n",
    "    \n",
    "# Длины циклов / рекорды\n",
    "def CL_criteria(num_of_cycles, n, N, alpha=0.05, print_mode=False):\n",
    "    if n not in E_prob_of_cycles:\n",
    "        E_prob_of_cycles[n] = [((1 / math.factorial(n)) * math_num.stirling(n, k, kind=1)) for k in range(len(num_of_cycles))]\n",
    "        with open('E_prob_of_cycles.pkl', 'wb') as f:\n",
    "            pickle.dump(E_prob_of_cycles, f)\n",
    "    E_num_of_cycles = [ x*N  for x in E_prob_of_cycles[n]]\n",
    "    (num_of_cycle_stat, cycle_array_len) = chi(num_of_cycles, E_num_of_cycles, print_mode)\n",
    "\n",
    "    cycle_quantile = chi2.ppf(1-alpha, df=cycle_array_len-1)\n",
    "    p_value = chi2.sf(float(num_of_cycle_stat), int(cycle_array_len-1))\n",
    "\n",
    "    if print_mode:\n",
    "        print(\"Квантиль степени \" + str(cycle_array_len - 1) + \" = \" + str(cycle_quantile))\n",
    "        print(\"Статистика для ровно k циклов = \" + str(num_of_cycle_stat))\n",
    "        print(\"p-value = \" + str(p_value))\n",
    "    else:\n",
    "        return (num_of_cycle_stat, cycle_quantile, p_value)\n",
    "\n",
    "# Кратчайший цикл имеет длину k ??????? n -> inf -> doesnt work\n",
    "def SC_criteria(num_shortest_cycle,  n, N, alpha=0.05, print_mode=False):\n",
    "    if n not in E_prob_of_shortest_cycle:\n",
    "        E_prob_of_shortest_cycle[n] = gen_prob_of_shortest_cycles2(n) # without 2 -> its coeff method\n",
    "        with open('E_prob_of_shortest_cycle.pkl', 'wb') as f:\n",
    "            pickle.dump(E_prob_of_shortest_cycle, f)\n",
    "    E_num_of_shortest_cycle = [ x*N  for x in E_prob_of_shortest_cycle[n]]\n",
    "\n",
    "    #num_shortest_cycle = gen_prob_of_shortest_cycles2(n)\n",
    "    #num_shortest_cycle = [ x*N  for x in num_shortest_cycle]\n",
    "\n",
    "    (shortest_cycle_stat, shortest_cycle_array_len) = chi(num_shortest_cycle, E_num_of_shortest_cycle, print_mode)\n",
    "\n",
    "    shortest_cycle_quantile = chi2.ppf(1-alpha, df=shortest_cycle_array_len-1)\n",
    "    p_value = chi2.sf(float(shortest_cycle_stat), int(shortest_cycle_array_len-1))\n",
    "    \n",
    "    if print_mode:\n",
    "        print(\"Квантиль степени \" + str(shortest_cycle_array_len - 1) + \" = \" + str(shortest_cycle_quantile))\n",
    "        print(\"Статистика для минимального цикла длины k = \" + str(shortest_cycle_stat))\n",
    "        print(\"p-value = \" + str(p_value))\n",
    "    else:\n",
    "        return (shortest_cycle_stat, shortest_cycle_quantile, p_value)\n",
    "\n",
    "# Количество инверсий N*K - dynamic programming mahonian row\n",
    "def Inv_criteria(num_of_inversions, n, N, alpha=0.05, print_mode=False):\n",
    "    if n not in E_prob_of_inversions:\n",
    "        E_prob_of_inversions[n] = [i/math.factorial(n) for i in gen_num_of_inversions(n)]\n",
    "        with open('E_prob_of_inversions.pkl', 'wb') as f:\n",
    "            pickle.dump(E_prob_of_inversions, f)\n",
    "    E_num_of_inversions = [i * N for i in E_prob_of_inversions[n]]\n",
    "    \n",
    "    (inversions_stat, inversions_array_len) = chi(num_of_inversions, E_num_of_inversions, print_mode)\n",
    "\n",
    "    inversions_quantile = chi2.ppf(1-alpha, df=inversions_array_len-1)\n",
    "    p_value = chi2.sf(float(inversions_stat), int(inversions_array_len-1))\n",
    "    \n",
    "    if print_mode:\n",
    "        print(\"Квантиль степени \" + str(inversions_array_len - 1) + \" = \" + str(inversions_quantile))\n",
    "        print(\"Статистика для минимального цикла длины k = \" + str(inversions_stat))\n",
    "        print(\"p-value = \" + str(p_value))\n",
    "    else:\n",
    "        return (inversions_stat, inversions_quantile, p_value)\n",
    "\n",
    "def Inv_criteria1024(num_of_inversions, n, N, alpha=0.05, print_mode=False):\n",
    "    if exists('./1024_mah.pkl'):\n",
    "        with open('1024_mah.pkl', 'rb') as f:\n",
    "            E_num_of_inversions = pickle.load(f)\n",
    "    else:\n",
    "        print(\"Criteria error file not found\")\n",
    "        return 0\n",
    "    E_num_of_inversions = [x/math.factorial(n) * N for x in E_num_of_inversions]\n",
    "    (inversions_stat, inversions_array_len) = chi(num_of_inversions, E_num_of_inversions, print_mode)\n",
    "\n",
    "    inversions_quantile = chi2.ppf(1-alpha, df=inversions_array_len-1)\n",
    "    p_value = chi2.sf(float(inversions_stat), int(inversions_array_len-1))\n",
    "    \n",
    "    if print_mode:\n",
    "        print(\"Квантиль степени \" + str(inversions_array_len - 1) + \" = \" + str(inversions_quantile))\n",
    "        print(\"Статистика для минимального цикла длины k = \" + str(inversions_stat))\n",
    "        print(\"p-value = \" + str(p_value))\n",
    "    else:\n",
    "        return (inversions_stat, inversions_quantile, p_value)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51404cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP_criteria(num_of_fixed_points, n, N, print_mode=True)\n",
    "# CL_criteria(num_of_cycles, n, N, print_mode=True)\n",
    "# SC_criteria(num_shortest_cycle, n, N, print_mode=True)\n",
    "# Inv_criteria(num_of_inversions, n, N, print_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e611870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59ee7e2e",
   "metadata": {},
   "source": [
    "## Show distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y - two arrays with distribution, r - first x label\n",
    "def compare_two_distr_graph(x, y, r=0):\n",
    "    df_to_show = pd.DataFrame(columns = ['D1', 'D2'])\n",
    "    df_to_show['D1'], df_to_show['D2'] = conv(x, y, 0.01)\n",
    "    df_to_show['D1'], df_to_show['D2'] = df_to_show['D1'].astype(float), df_to_show['D2'].astype(float)\n",
    "    df_to_show['x'] = [k for k in range(0, len(df_to_show))]\n",
    "    print(df_to_show)\n",
    "    xticklabels= [k for k in range(r, len(df_to_show)+r)]\n",
    "    xticklabels[len(df_to_show)-1] = '>' + str(len(df_to_show)+r-1)\n",
    "    width = 0.8\n",
    "    matplotlib.rc_file_defaults()\n",
    "    ax = sns.set_style(style=\"whitegrid\", rc=None)\n",
    "    fig, ax = plt.subplots(figsize=(13,7))\n",
    "    ax_twin = ax.twinx()\n",
    "    sns.barplot(data = df_to_show, x='x', y='D1', alpha=0.8, ax=ax, color = 'blue', width=width)\n",
    "    sns.barplot(data = df_to_show, x='x', y='D2', alpha=0.8, ax=ax, color = 'red', width=width).set(xlabel = \"Number of points\",ylabel='Probabilty', xticklabels=xticklabels)\n",
    "        \n",
    "    sns.lineplot(data = df_to_show, x='x', y='D1', marker='o', err_style='bars', color = 'blue', ax=ax_twin, sort = False, linewidth = 4, markersize=7).set(ylabel='Probabilty')\n",
    "    sns.lineplot(data = df_to_show, x='x', y='D2', marker='o', err_style='bars', color = 'red', ax=ax_twin, sort = False, linewidth = 4, markersize=7).set(title='Expected and observed probability distribution for fixed points', yticklabels=[], ylabel=None)\n",
    "     \n",
    "    max_x = len(df_to_show)\n",
    "    max_y = max(max(df_to_show['D1']), max(df_to_show['D2']))*1.1\n",
    "    ax.set_xlim([-width, max_x])\n",
    "    ax.set_ylim([0, max_y])\n",
    "    ax_twin.set_xlim([-width, max_x])\n",
    "    ax_twin.set_ylim([0, max_y])\n",
    "    ax.legend() ## add legend\n",
    "\n",
    "if n not in E_prob_of_shortest_cycle:\n",
    "        E_prob_of_shortest_cycle[n] = gen_prob_of_shortest_cycles2(n) # without 2 -> its coeff method\n",
    "        with open('E_prob_of_shortest_cycle.pkl', 'wb') as f:\n",
    "            pickle.dump(E_prob_of_shortest_cycle, f)\n",
    "E_num_of_shortest_cycle = [ x*N  for x in E_prob_of_shortest_cycle[n]]\n",
    "compare_two_distr_graph(num_of_shortest_cycle, E_num_of_shortest_cycle, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c561e3c8",
   "metadata": {},
   "source": [
    "## Correlation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe166be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_records(permutation: Permutation): \n",
    "    maximum = -1\n",
    "    records = 0 \n",
    "    for index, elem in enumerate(permutation.list()): \n",
    "         if elem > maximum: \n",
    "            records += 1\n",
    "            maximum = elem    \n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c0ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling(column):\n",
    "    return (column - column.min()) / (column.max() - column.min())\n",
    "\n",
    "def calculate_avg_length(a):\n",
    "    r = k = 0\n",
    "    for i in a:\n",
    "        r += k*i\n",
    "        k += 1\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f1c83e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correlation table\n",
    "\n",
    "corr_df = pd.DataFrame(columns=['n','N','FP & SC', 'FP & Rec', 'FP & NoC', 'FP & Ord', 'FP & Inv', 'FP & Evn',\n",
    "                                'SC & NoC', 'SC & Rec', 'SC & Ord', 'SC & Inv', 'SC & Evn', 'Rec & NoC',\n",
    "                                'Rec & Ord', 'Rec & Inv', 'Rec & Evn', 'NoC & Ord', 'NoC & Inv', 'NoC & Evn',\n",
    "                                'Ord & Inv', 'Ord & Evn', 'Inv & Evn'])\n",
    "\n",
    "# длина подстановки n\n",
    "# длина выборки N\n",
    "n_N_values = [\n",
    "              (500, 150000),\n",
    "              (1000, 150000),\n",
    "             ]\n",
    "\n",
    "n_N_values2 = [(2**9, 1000), (2**9, 5000), (2**9, 12000), \n",
    "              (2**10, 1000), (2**10, 5000), (2**10, 12000),\n",
    "              (2**11, 1000), (2**11, 5000), (2**11, 12000),\n",
    "             ]\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "for p in n_N_values:\n",
    "    \n",
    "    n, N = p\n",
    "    \n",
    "    # 'Fixed points','Shortest cycle','Records', 'Number of cycles', 'Order', 'Inversions', 'Even'\n",
    "    df = pd.DataFrame(columns=['FP','SC','Rec', 'NoC', 'Ord', 'Inv', 'Evn'])\n",
    "\n",
    "    num_of_cycles = 0\n",
    "    num_of_fixed_points = 0\n",
    "    length_of_shortes_cycle = 0\n",
    "    order = 1\n",
    "    even = 0\n",
    "    inversions = 0\n",
    "    \n",
    "    for i in tqdm(range(N)):\n",
    "        a = Permutation(np.random.permutation(n))\n",
    "        num_of_cycles = a.cycles\n",
    "        if 1 in a.cycle_structure.keys():\n",
    "            num_of_fixed_points = a.cycle_structure[1]\n",
    "        else:\n",
    "            num_of_fixed_points = 0\n",
    "        length_of_shortes_cycle = min(a.cycle_structure.keys())\n",
    "        num_of_records = count_records(a)\n",
    "        order = 1\n",
    "        for x in list(a.cycle_structure.keys()):\n",
    "            order = np.lcm(order, x)\n",
    "        even = a.is_even\n",
    "        inversions = a.inversions()\n",
    "        df.loc[len(df)] = [num_of_fixed_points, length_of_shortes_cycle, num_of_records, num_of_cycles, order, inversions, even]        \n",
    "            \n",
    "    print(\"n=\"+ str(n), \"N=\" + str(N), \" - Done,\" + \" Time: \" + str(round(time.perf_counter() - t1, 1)))\n",
    "    df = df.astype({\"Evn\": int})\n",
    "    #for col in df.columns:\n",
    "    #    df[col] = min_max_scaling(df[col])\n",
    "    cm = df.corr()\n",
    "    corr_df.loc[len(corr_df)] = [n, N, cm['FP']['SC'], cm['FP']['Rec'], cm['FP']['NoC'], cm['FP']['Ord'], cm['FP']['Inv'],\n",
    "                                 cm['FP']['Evn'], cm['SC']['Rec'], cm['SC']['NoC'], cm['SC']['Ord'], cm['SC']['Inv'], cm['SC']['Evn'],\n",
    "                                 cm['Rec']['NoC'], cm['Rec']['Ord'], cm['Rec']['Inv'], cm['Rec']['Evn'], cm['NoC']['Ord'],\n",
    "                                 cm['NoC']['Inv'], cm['NoC']['Evn'], cm['Ord']['Inv'], cm['Ord']['Evn'], cm['Inv']['Evn'],\n",
    "                                ]\n",
    "\n",
    "\n",
    "corr_df = corr_df.round(3)\n",
    "corr_df = corr_df.astype({\"n\": int, \"N\": int})\n",
    "# df.to_csv(\"./df.csv\", index=None)  \n",
    "# df.to_csv(\"./df.csv\", index=None, mode='a', header=None)  \n",
    "# corr_df.to_csv(\"./corr.csv\", index=None)  \n",
    "corr_df.to_csv(\"./corr.csv\", index=None, mode='a', header=None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66ea627",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c0d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_N_values = [(2**9, 1000), (2**9, 5000), (2**9, 12000), \n",
    "              (2**10, 1000), (2**10, 5000), (2**10, 12000),\n",
    "              (2**11, 1000), (2**11, 5000), (2**11, 12000),\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb6c86f",
   "metadata": {},
   "source": [
    "## n ~ N relationship chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5f27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_N_values = [ (25, 2**10), (25, 2**12), (25, 2**14), (25, 2**16), \n",
    "              (50, 2**10), (50, 2**12), (50, 2**14), (50, 2**16), \n",
    "              (100, 2**10), (100, 2**12), (100, 2**14), (100, 2**16), (100, 2**18),\n",
    "              (200, 2**10), (200, 2**14), (200, 2**16), (200, 2**18),\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ccf86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82061893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s - statistic, q - quantile, p - p-value\n",
    "j_max = 10\n",
    "\n",
    "for p in n_N_values:\n",
    "    n, N = p\n",
    "    df = pd.DataFrame(columns=['n', 'N', 'aFP-s', 'aFP-q', 'aFP-p', 'aCL-s', 'aCL-q', 'aCL-p', 'aSC-s', 'aSC-q', 'aSC-p', 'aInv-s', 'aInv-q', 'aInv-p', 'FP s<q', 'CL s<q', 'SC s<q', 'Inv s<q'])\n",
    "    fp = [np.zeros(j_max), np.zeros(j_max), np.zeros(j_max)] # 0 - stat, 1 - quantile, 2 - p-value\n",
    "    cl = [np.zeros(j_max), np.zeros(j_max), np.zeros(j_max)]\n",
    "    sc = [np.zeros(j_max), np.zeros(j_max), np.zeros(j_max)]\n",
    "    inv = [np.zeros(j_max), np.zeros(j_max), np.zeros(j_max)]\n",
    "    f = np.array([0, 0, 0, 0])\n",
    "    for j in range(j_max):\n",
    "        num_of_cycles = [0 for k in range(n+1)]\n",
    "        num_of_fixed_points = [0 for k in range(n+1)]\n",
    "        num_shortest_cycle = [0 for k in range(n+1)]\n",
    "        num_of_inversions = [0 for k in range(int(n*(n-1)/2) + 1)]\n",
    "                    \n",
    "        for i in tqdm(range(N)):\n",
    "            a = Permutation(np.random.permutation(n))\n",
    "            cycle_num = a.cycles\n",
    "            num_of_cycles[a.cycles] += 1\n",
    "            if 1 in a.cycle_structure.keys():\n",
    "                num_of_fixed_points[a.cycle_structure[1]]  += 1\n",
    "            else:\n",
    "                num_of_fixed_points[0] += 1\n",
    "            num_shortest_cycle[min(a.cycle_structure.keys())] += 1     \n",
    "            num_of_inversions[a.inversions()] += 1\n",
    "                    \n",
    "        print(1)\n",
    "        fp[0][j], fp[1][j], fp[2][j] = FP_criteria(num_of_fixed_points, n, N)\n",
    "        print(2)\n",
    "        cl[0][j], cl[1][j], cl[2][j] = CL_criteria(num_of_cycles, n, N)\n",
    "        print(3)\n",
    "        sc[0][j], sc[1][j], sc[2][j] = SC_criteria(num_shortest_cycle, n, N)\n",
    "        print(4)\n",
    "        inv[0][j], inv[1][j], inv[2][j] = Inv_criteria(num_of_inversions, n, N)\n",
    "        print(5)\n",
    "            \n",
    "        f[0] += int(fp[0][j] < fp[1][j])\n",
    "        f[1] += int(cl[0][j] < cl[1][j])\n",
    "        f[2] += int(sc[0][j] < sc[1][j])\n",
    "        f[3] += int(inv[0][j] < inv[1][j])\n",
    "            \n",
    "        #if (fp[0].mean() < fp[1].mean()) & (cl[0].mean() < cl[1].mean()) & (sc[0].mean() < sc[1].mean()) & (inv[0].mean() < inv[1].mean()):  \n",
    "        #    f = False\n",
    "        \n",
    "    df.loc[len(df)] = [n, N, fp[0].mean(), fp[1].mean(), fp[2].mean(), cl[0].mean(), cl[1].mean(), cl[2].mean(),\n",
    "                             sc[0].mean(), sc[1].mean(), sc[2].mean(), inv[0].mean(), inv[1].mean(), inv[2].mean(),\n",
    "                             f[0],  f[1],  f[2],  f[3]]\n",
    "    print('n =', n, 'N =', N, 'Done = ' + str(f))    \n",
    "    df = df.round(3)\n",
    "    df = df.astype({\"n\": int, \"N\": int, 'FP s<q':int, 'CL s<q':int, 'SC s<q':int, 'Inv s<q':int})\n",
    "    df.to_csv(\"./df_n_N.csv\", index=None, mode='a', header=None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c8ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y - two arrays with distribution, r - first x label\n",
    "def corr_table(x, y, r=0):\n",
    "    df_to_show = pd.DataFrame(columns = ['D1', 'D2'])\n",
    "    df_to_show['D1'], df_to_show['D2'] = conv(x, y, 0.01)\n",
    "    df_to_show['D1'], df_to_show['D2'] = df_to_show['D1'].astype(float), df_to_show['D2'].astype(float)\n",
    "    df_to_show['x'] = [k for k in range(0, len(df_to_show))]\n",
    "    print(df_to_show)\n",
    "    xticklabels= [k for k in range(r, len(df_to_show)+r)]\n",
    "    xticklabels[len(df_to_show)-1] = '>' + str(len(df_to_show)+r-1)\n",
    "    width = 0.8\n",
    "    matplotlib.rc_file_defaults()\n",
    "    ax = sns.set_style(style=\"whitegrid\", rc=None)\n",
    "    fig, ax = plt.subplots(figsize=(13,7))\n",
    "    # ax_twin = ax.twinx()\n",
    "    # sns.barplot(data = df_to_show, x='x', y='D1', alpha=0.8, ax=ax, color = 'blue', width=width)\n",
    "    # sns.barplot(data = df_to_show, x='x', y='D2', alpha=0.8, ax=ax, color = 'red', width=width).set(xlabel = \"Number of points\",ylabel='Probabilty', xticklabels=xticklabels)\n",
    "        \n",
    "    sns.lineplot(data = df_to_show, x='x', y='D1', marker='o', err_style='bars', color = 'blue', ax=ax_twin, sort = False, linewidth = 4, markersize=7).set(ylabel='Probabilty')\n",
    "    sns.lineplot(data = df_to_show, x='x', y='D2', marker='o', err_style='bars', color = 'red', ax=ax_twin, sort = False, linewidth = 4, markersize=7).set(title='Expected and observed probability distribution for fixed points', yticklabels=[], ylabel=None)\n",
    "     \n",
    "    max_x = len(df_to_show)\n",
    "    max_y = max(max(df_to_show['D1']), max(df_to_show['D2']))*1.1\n",
    "    ax.set_xlim([-width, max_x])\n",
    "    ax.set_ylim([0, max_y])\n",
    "    ax_twin.set_xlim([-width, max_x])\n",
    "    ax_twin.set_ylim([0, max_y])\n",
    "    ax.legend() ## add legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de588e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.read_csv(\"./corr.csv\") \n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = corr_df.melt(id_vars=['n', 'N'], var_name='Values name', value_name='Corr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad42fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# For each set of style and range settings, plot n random points in the box\n",
    "# defined by x in [23, 32], y in [0, 100], z in [zlow, zhigh].\n",
    "\n",
    "fig = px.scatter_3d(corr_df, x='n', y='N', z='Corr', color='Values name', title='Correlation between 7 main characteristics')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d24cc",
   "metadata": {},
   "source": [
    "## Expirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f4183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import sys\n",
    "import random\n",
    "import functools\n",
    "import bitarray\n",
    "from bitarray.util import int2ba\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def gen_permutation(f):\n",
    "    res = np.empty(N)\n",
    "    for el in range(N):\n",
    "        res[el] = f(el)\n",
    "    return res\n",
    "\n",
    "\n",
    "def gen_quasigroup(f, phi, psy, pls):\n",
    "    def g(x, y):\n",
    "        return f(pls(phi(x), psy(y)))\n",
    "    return g\n",
    "\n",
    "\n",
    "def bijection(permutation):\n",
    "    def f(x):\n",
    "        return permutation[x]\n",
    "    return f\n",
    "\n",
    "\n",
    "def random_bijection(n):\n",
    "    perm = np.random.permutation(n)\n",
    "    return bijection(perm)\n",
    "\n",
    "\n",
    "def left_shift(f, el):\n",
    "    def g(x):\n",
    "        return f(el, x)\n",
    "    return g\n",
    "\n",
    "\n",
    "def right_shift(f, el):\n",
    "    def g(x):\n",
    "        return f(x, el)\n",
    "    return g\n",
    "\n",
    "\n",
    "def multiple_left_shifts(*args, f):\n",
    "    def g(x):\n",
    "        res = x\n",
    "        for el in args:\n",
    "            res = f(el, x)\n",
    "    return g\n",
    "\n",
    "\n",
    "def multiple_right_shifts(*args, f):\n",
    "    def g(x):\n",
    "        res = x\n",
    "        for el in args:\n",
    "            res = f(x, el)\n",
    "    return g\n",
    "\n",
    "\n",
    "def pi():\n",
    "    X = bitarray.bitarray([random.choice([True, False]) for _ in range(4)])\n",
    "    def f(x, y):\n",
    "        return X[2*x + y]\n",
    "    return f\n",
    "\n",
    "\n",
    "def good_pi():\n",
    "    pi_funcs = [\n",
    "                lambda x, y: x and y,\n",
    "                lambda x, y: (x and y) ^ 1,\n",
    "                lambda x, y: (x and y) ^ x,\n",
    "                lambda x, y: (x and y) ^ y,\n",
    "                lambda x, y: (x and y) ^ x ^ 1,\n",
    "                lambda x, y: (x and y) ^ y ^ 1,\n",
    "                lambda x, y: x ^ y,\n",
    "                lambda x, y: x ^ y ^ 1,\n",
    "                lambda x, y: (x and y) ^ x ^ y\n",
    "            ]\n",
    "    return pi_funcs[np.random.randint(0, 9)]\n",
    "\n",
    "\n",
    "def quad_functions(args, i):\n",
    "    ln = len(args)\n",
    "    res = functools.reduce(lambda x, y: x != y, args[:i], False)\n",
    "    res = functools.reduce(lambda x, y: x != y, [args[j] and args[k] for j in range(ln) for k in range(j) if (k != i and j != i)], res)\n",
    "    return res\n",
    "\n",
    "\n",
    "def triangle_functions(args, i):\n",
    "    return random_bool_function(i - 1)(args[:i])\n",
    "\n",
    "\n",
    "def random_bool_function(n: int): \n",
    "    N = 1 << n\n",
    "    X = int2ba(random.randint(0, N-1), length = N)\n",
    "\n",
    "    def f(args: bitarray.bitarray): \n",
    "        return X[sum([(1<<i) * el for i, el in enumerate(args)])]\n",
    "    return f\n",
    "\n",
    "\n",
    "def quasigroup_operation_quad(is_good_pi: bool = False):\n",
    "    if not is_good_pi:\n",
    "        rnd_fs = [good_pi() for _ in range(n)]\n",
    "    else: \n",
    "        rnd_fs = [pi() for _ in range(n)]\n",
    "\n",
    "    def f(x, y):\n",
    "        X, Y = int2ba(x, length=n), int2ba(y, length=n)\n",
    "        args = [f(x_i, y_i) for f, x_i, y_i in zip(rnd_fs, X, Y)]\n",
    "        res = 0\n",
    "        for i in range(n):\n",
    "            res += (1 << (n - 1 - i)) * quad_functions(args, i)\n",
    "        return res ^ x ^ y\n",
    "    return f\n",
    "\n",
    "def quasigroup_operation_triangle(is_good_pi: bool = False):\n",
    "    if not is_good_pi:\n",
    "        rnd_fs = [good_pi() for _ in range(n)]\n",
    "    else: \n",
    "        rnd_fs = [pi() for _ in range(n)]\n",
    "\n",
    "    family = [random_bool_function(i) for i in range(n)]\n",
    "\n",
    "    def f(x, y):\n",
    "        X, Y = int2ba(x, length=n), int2ba(y, length=n)\n",
    "        args = [f(x_i, y_i) for f, x_i, y_i in zip(rnd_fs, X, Y)]\n",
    "        res = 0\n",
    "        for i in range(n):\n",
    "            res += (1 << (n - 1 - i)) * family[i](args[:i])\n",
    "        return res ^ x ^ y\n",
    "    return f\n",
    "\n",
    "\n",
    "def shuffle_arguments(f):\n",
    "    shfl = bijection(np.random.permutation(ln))\n",
    "    def g(args, i):\n",
    "        ln = len(args)\n",
    "        new_args = bitarray.bitarray(ln)\n",
    "        for i in range(ln):\n",
    "            new_args[i] = args[shfl(i)]\n",
    "        return f(new_args, i)\n",
    "    return g\n",
    "\n",
    "\n",
    "n = 10\n",
    "N = 1 << n\n",
    "\n",
    "\n",
    "f_1, f_2, f_3 = [random_bijection(N) for _ in range(3)]\n",
    "op = operator.xor\n",
    "a = random.randint(0, N-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdac10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists('./permutations.pkl'):\n",
    "    with open('permutations.pkl', 'rb') as f:\n",
    "        PERM = pickle.load(f)\n",
    "else:\n",
    "    permutations = []\n",
    "    for iteration in tqdm(range(500)):\n",
    "        f1, f2, f3 = [random_bijection(N) for _ in range(3)]\n",
    "        o = gen_quasigroup(f1, f2, f3, operator.xor)\n",
    "        for _ in range(24):\n",
    "            shift = left_shift(o, random.randint(0, N-1))\n",
    "            permutations.append(Permutation(gen_permutation(shift))) ## Это записываем\n",
    "            #print(p)\n",
    "\n",
    "    permutations_2 = []\n",
    "    for iteration in tqdm(range(12000)):\n",
    "        op = quasigroup_operation_quad()\n",
    "        for i in range(1): ## Используем каждую операцию по одному разу\n",
    "            shift = left_shift(op, random.randint(0, N - 1))\n",
    "            permutations_2.append(Permutation(gen_permutation(shift)))\n",
    "\n",
    "    permutations_3 = []\n",
    "    for iteration in tqdm(range(500)):\n",
    "        f1, f2, f3 = [random_bijection(N) for _ in range(3)]\n",
    "        o = gen_quasigroup(f1, f2, f3, lambda x, y: (x+y) % N)\n",
    "        for _ in range(24):\n",
    "            shift = left_shift(o, random.randint(0, N-1))\n",
    "            permutations_3.append(Permutation(gen_permutation(shift))) ## Это записываем\n",
    "\n",
    "    permutations_4 = []\n",
    "\n",
    "    for iteration in tqdm(range(12000)):\n",
    "        op = quasigroup_operation_triangle()\n",
    "        for i in range(1): ## Используем каждую операцию по одному разу\n",
    "            shift = left_shift(op, random.randint(0, N - 1))\n",
    "            permutations_4.append(Permutation(gen_permutation(shift)))\n",
    "    \n",
    "    PERM = [permutations, permutations_2, permutations_3, permutations_4]\n",
    "    with open('permutations.pkl', 'wb') as f:\n",
    "            pickle.dump(PERM, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERM1 = PERM.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85cef27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b577220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e0b9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e0ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s - statistic, q - quantile, p - p-value\n",
    "j_max = 1\n",
    "n = 2**10\n",
    "N = 12000\n",
    "    \n",
    "for c in range(1, 5):\n",
    "        df = pd.DataFrame(columns=['type', 'n', 'N', 'FP-s', 'FP-q', 'FP-p', 'CL-s', 'CL-q', 'Rec-p', 'Rec-s', 'Rec-q', 'CL-p', 'SC-s', 'SC-q', 'SC-p', 'Inv-s', 'Inv-q', 'Inv-p', 'FP s<q', 'CL s<q', 'Rec s<q', 'SC s<q', 'Inv s<q'])\n",
    "        fp = [np.zeros(j_max), np.zeros(j_max), np.zeros(j_max)] # 0 - stat, 1 - quantile, 2 - p-value\n",
    "        cl = [np.zeros(j_max), np.zeros(j_max), np.zeros(j_max)]\n",
    "        rec = [np.zeros(j_max), np.zeros(j_max), np.zeros(j_max)]\n",
    "        sc = [np.zeros(j_max), np.zeros(j_max), np.zeros(j_max)]\n",
    "        inv = [np.zeros(j_max), np.zeros(j_max), np.zeros(j_max)]\n",
    "        f = np.array([0, 0, 0, 0, 0])\n",
    "        for j in range(j_max):\n",
    "            num_of_cycles = [0 for k in range(n+1)]\n",
    "            num_of_fixed_points = [0 for k in range(n+1)]\n",
    "            num_shortest_cycle = [0 for k in range(n+1)]\n",
    "            num_of_inversions = [0 for k in range(int(n*(n-1)/2) + 1)]\n",
    "            num_of_records = [0 for k in range(n+1)]\n",
    "            \n",
    "            for i in tqdm(range(N)):\n",
    "                \n",
    "                a = PERM[c-1][i]\n",
    "                \n",
    "                cycle_num = a.cycles\n",
    "                num_of_cycles[a.cycles] += 1\n",
    "                if 1 in a.cycle_structure.keys():\n",
    "                    num_of_fixed_points[a.cycle_structure[1]]  += 1\n",
    "                else:\n",
    "                    num_of_fixed_points[0] += 1\n",
    "                num_shortest_cycle[min(a.cycle_structure.keys())] += 1     \n",
    "                num_of_inversions[a.inversions()] += 1\n",
    "                num_of_records[count_records(a)] += 1\n",
    "                \n",
    "\n",
    "            fp[0][j], fp[1][j], fp[2][j] = FP_criteria(num_of_fixed_points, n, N)\n",
    "            cl[0][j], cl[1][j], cl[2][j] = CL_criteria(num_of_cycles, n, N)\n",
    "            rec[0][j], rec[1][j], rec[2][j] = CL_criteria(num_of_records, n, N)\n",
    "            sc[0][j], sc[1][j], sc[2][j] = SC_criteria(num_shortest_cycle, n, N)\n",
    "            inv[0][j], inv[1][j], inv[2][j] = Inv_criteria1024(num_of_inversions, n, N)\n",
    "\n",
    "            f[0] += int(fp[0][j] < fp[1][j])\n",
    "            f[1] += int(cl[0][j] < cl[1][j])\n",
    "            f[2] += int(rec[0][j] < rec[1][j])\n",
    "            f[3] += int(sc[0][j] < sc[1][j])\n",
    "            f[4] += int(inv[0][j] < inv[1][j])\n",
    "\n",
    "        df.loc[len(df)] = [c, n, N, fp[0].mean(), fp[1].mean(), fp[2].mean(), cl[0].mean(), cl[1].mean(), cl[2].mean(), rec[0].mean(), rec[1].mean(), rec[2].mean(), \n",
    "                                 sc[0].mean(), sc[1].mean(), sc[2].mean(), inv[0].mean(), inv[1].mean(), inv[2].mean(),\n",
    "                                 f[0],  f[1],  f[2],  f[3], f[4]]\n",
    "        print('type', c,'n =', n, 'N =', N, 'Done = ' + str(f))    \n",
    "        df = df.round(3)\n",
    "        df = df.astype({\"type\": int, \"n\": int, \"N\": int, 'FP s<q':int, 'CL s<q':int, 'SC s<q':int, 'Inv s<q':int})\n",
    "        df.to_csv(\"./df_experiment.csv\", index=None)  \n",
    "        # df.to_csv(\"./df_experiment.csv\", index=None, mode='a', header=None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8337a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERM[3][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f0003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
